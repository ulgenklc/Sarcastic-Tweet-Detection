{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Twitter Sentiment Analysis\n\n**By Neuromatch Academy**\n\n__Content creators:__  Juan Manuel Rodriguez, Salomey Osei, Gonzalo Uribarri","metadata":{"id":"ca_6w0MZ2C76"}},{"cell_type":"markdown","source":"**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n\n<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>","metadata":{"id":"sKcIXMtu4IIj"}},{"cell_type":"markdown","source":"---\n# Step 1: Questions and goals\n\n* Can we infer emotion from a tweet text?\n* How words are distributed accross the dataset?\n* Are words related to one kind of emotion?","metadata":{"id":"qPDnA4tP4O8d"}},{"cell_type":"markdown","source":"---\n# Step 2: Literature review\n\n[Original Dataset Paper](https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf)\n\n[Papers with code](https://paperswithcode.com/dataset/imdb-movie-reviews)","metadata":{"id":"Yz2milFF4Q9a"}},{"cell_type":"markdown","source":"---\n# Step 3: Load and explore the dataset","metadata":{"id":"j3MSPcueSiSN"}},{"cell_type":"markdown","source":"##  Install dependencies\n","metadata":{"id":"TWEPUsg8pUyc"}},{"cell_type":"code","source":"# @title Install dependencies\n# !pip install pandas --quiet\n# !pip install torchtext --quiet","metadata":{"id":"vjyDH-sH6Rsa","tags":["hide-input"],"execution":{"iopub.status.busy":"2021-08-12T15:09:43.781379Z","iopub.execute_input":"2021-08-12T15:09:43.781862Z","iopub.status.idle":"2021-08-12T15:09:43.78688Z","shell.execute_reply.started":"2021-08-12T15:09:43.781762Z","shell.execute_reply":"2021-08-12T15:09:43.785699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We import some libraries to load the dataset\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom collections import Counter\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\nimport torchtext\nfrom torchtext.data import get_tokenizer\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport cudf\n\nimport requests, zipfile, io\n\nimport re\nimport nltk\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('stopwords')\nimport string\n\nfrom ast import literal_eval\nimport gc","metadata":{"id":"-fZ9-oUPZCnN","execution":{"iopub.status.busy":"2021-08-16T13:40:19.409879Z","iopub.execute_input":"2021-08-16T13:40:19.410312Z","iopub.status.idle":"2021-08-16T13:40:25.444546Z","shell.execute_reply.started":"2021-08-16T13:40:19.410215Z","shell.execute_reply":"2021-08-16T13:40:25.442909Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You can find the dataset we are going to use in [this website](http://help.sentiment140.com/for-students/).","metadata":{"id":"yImD1N69kBcK"}},{"cell_type":"markdown","source":"**SECTION A**","metadata":{}},{"cell_type":"code","source":"# USE THIS WHEN TWITTER DATA SET IS NOT AVAILABLE, IF ALREADY AVAILABLE LOAD FROM THE DIRECTORY\nurl = 'http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip'\nr = requests.get(url)\nz = zipfile.ZipFile(io.BytesIO(r.content))\nz.extractall()\n\n# We load the dataset\nheader_list = [\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"]\ndf = pd.read_csv('training.1600000.processed.noemoticon.csv',\n                 encoding = \"ISO-8859-1\", names=header_list)\n\n# Let's have a look at it\ndf.head()","metadata":{"id":"1KCH2amLNcZH","execution":{"iopub.status.busy":"2021-08-12T15:09:53.928996Z","iopub.execute_input":"2021-08-12T15:09:53.929338Z","iopub.status.idle":"2021-08-12T15:10:00.960086Z","shell.execute_reply.started":"2021-08-12T15:09:53.929308Z","shell.execute_reply":"2021-08-12T15:10:00.959182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SECTION A.1**","metadata":{}},{"cell_type":"code","source":"# IF THE DATA LOADED IS UNPROCESSED USE THE FOLLOWING CODE TO PROCESS DATA, \n# IF PROCESSED DATA IS AVAILABLE SKIP THIS SECTION AND CONTINUE AT SECTION B\n######################################################################################\n#Lets make a copy of the data set before playing around with it\ndf1 = df.copy()\n\n######################################################################################\n#remove URLs\npattern=r'(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))';\ndef rem_url(x):\n  match = re.findall(pattern, x)\n  for m in match:\n    url = m[0]\n    x = x.replace(url, '')\n  return x\ndf1['url_removed'] = df1['text'].apply(lambda x:rem_url(x))\n# df1.head()\nprint('URL removed')\n\n######################################################################################\n#remove twitter handles from text\ntknzr = TweetTokenizer(strip_handles=True)\ndf1['handle_removed'] = df1['url_removed'].apply(lambda x:tknzr.tokenize(x))\n# df1.head()\nprint('Twitter Handles removed')\n# detokenize the tweet again\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\ndf1['orig'] = df1['handle_removed'].apply(lambda x:TreebankWordDetokenizer().detokenize(x))\nprint('Tweets detokenized again')\n\n######################################################################################\n# remove punctuations\nstring.punctuation\ndef remove_punctuation(text):\n    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree\ndf1['clean_msg']= df1['orig'].apply(lambda x:remove_punctuation(x))\n# df1.head()\nprint('Punctuation removed')\n\n######################################################################################\n# delete the unnecessary columns\ndel df1['url_removed']\ndel df1['handle_removed']\ndel df1['orig']\n\n######################################################################################\n# remove the upper case letters\ndf1['msg_lower'] = df1['clean_msg'].apply(lambda x: x.lower())\nprint('All set to lower case')\n\n######################################################################################\n# tokenize\ndef tokenization(text):\n    tokens = re.split('W+',text)\n    return tokens\n#applying function to the column\ntknzr = TweetTokenizer(strip_handles=True)\ndf1['msg_tokenied'] = df1['msg_lower'].apply(lambda x:tknzr.tokenize(x))\nprint('Tweet tokenized again')\n\n######################################################################################\n# removing stop words\n#Stop words present in the library\nstopwords = nltk.corpus.stopwords.words('english')\n#defining the function to remove stopwords from tokenized text\ndef remove_stopwords(text):\n    output= [i for i in text if i not in stopwords]\n    return output\n#applying the function\ndf1['no_stopwords']= df1['msg_tokenied'].apply(lambda x:remove_stopwords(x))\nprint('Stopwords removed')\n\n######################################################################################\n#importing the Stemming function from nltk library\n#defining the object for stemming\nporter_stemmer = PorterStemmer()\n#defining a function for stemming\ndef stemming(text):\n  stem_text = [porter_stemmer.stem(word) for word in text]\n  return stem_text\ndf1['msg_stemmed']=df1['no_stopwords'].apply(lambda x: stemming(x))\nprint('Tweets stemmed')\n\n######################################################################################\n#defining the object for Lemmatization\nwordnet_lemmatizer = WordNetLemmatizer()\n# nltk.download('wordnet')\n#defining the function for lemmatization\ndef lemmatizer(text):\n  lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n  return lemm_text\ndf1['msg_lemmatized']=df1['no_stopwords'].apply(lambda x:lemmatizer(x))\nprint('Tweets Lemmatized')\n\n######################################################################################\n# Let's create a 3rd copy of the processed dataset and continue to work with it and modifying it for legibility\ndf2 = df1.copy()\ndf2.head()","metadata":{"id":"nWGfZbNBpc_v","execution":{"iopub.status.busy":"2021-08-12T15:10:06.967273Z","iopub.execute_input":"2021-08-12T15:10:06.967727Z","iopub.status.idle":"2021-08-12T15:25:44.975102Z","shell.execute_reply.started":"2021-08-12T15:10:06.967691Z","shell.execute_reply":"2021-08-12T15:25:44.974026Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SECTION A.2**","metadata":{}},{"cell_type":"code","source":"# delete unneccessary columns\ndel df2['msg_lower']\ndel df2['text']\ndel df2['clean_msg']\ndel df\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T15:26:13.466814Z","iopub.execute_input":"2021-08-12T15:26:13.467172Z","iopub.status.idle":"2021-08-12T15:26:13.55498Z","shell.execute_reply.started":"2021-08-12T15:26:13.467132Z","shell.execute_reply":"2021-08-12T15:26:13.553983Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SECTION A.3**","metadata":{}},{"cell_type":"code","source":"# Save the dataframe as a CSV file if not doens already\ndf2.to_csv('preprocessed_training_data_v2.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-16T13:41:09.452188Z","iopub.execute_input":"2021-08-16T13:41:09.452543Z","iopub.status.idle":"2021-08-16T13:41:09.647831Z","shell.execute_reply.started":"2021-08-16T13:41:09.452509Z","shell.execute_reply":"2021-08-16T13:41:09.646430Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-39bf7cfb04cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the dataframe as a CSV file if not doens already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessed_training_data_v2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"],"ename":"NameError","evalue":"name 'df2' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"**Section B**","metadata":{}},{"cell_type":"code","source":"# START FROM HERE IF ALREADY PROCESSED DATASET IS AVAILABLE FOR RUNNING RNN MODELS\n# Note the upload from drive results in the columns being read as a whole string,\n# intead use literal_eval to convert them to list.\n# But since this steps requires an insane amount of RAM, do it only for the column you intend to use for RNN.\n# Choose from the following [\"msg_tokenied\", \"no_stopwords\": literal_eval, \"msg_stemmed\": literal_eval,\"msg_lemmatized\"]\ncolumns = [\"msg_tokenied\",  # 0\n           \"no_stopwords\",  # 1\n           \"msg_stemmed\",   # 2\n           \"msg_lemmatized\" # 3\n          ]\ncolumn_of_interest = columns[0]\ndf2 = pd.read_csv(\"../input/twittertrainingpreprocessed/preprocessed_training_data_v2.csv\", index_col = 0,\n                  converters={column_of_interest: literal_eval}\n                 )\n\ngc.collect()\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T11:27:59.190533Z","iopub.execute_input":"2021-08-16T11:27:59.19088Z","iopub.status.idle":"2021-08-16T11:28:56.117356Z","shell.execute_reply.started":"2021-08-16T11:27:59.19085Z","shell.execute_reply":"2021-08-16T11:28:56.116412Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SECTION B.1**\n\nPrepare the data for putting it in the model","metadata":{}},{"cell_type":"code","source":"# Choose the column that you want to feed into the RNN model later on here\nX = df2.msg_tokenied.values\n# Changes values from [0,4] to [0,1]\ny = (df2.polarity.values > 1).astype(int)\n\n# Split the data into train and test\nx_train_text, x_test_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n\n# # print out the sample data set\n# for s, l in zip(x_train_text[:5], y_train[:5]):\n#   print('{}: {}'.format(l, s))\n\nx_train_token = x_train_text\nx_test_token = x_test_text\n\n# create a word counter\nwords = Counter()\nfor s in x_train_token:\n  for w in s:\n    words[w] += 1\n    \n#sort the words\nsorted_words = list(words.keys())\nsorted_words.sort(key=lambda w: words[w], reverse=True)\nprint(f\"Number of different Tokens in our Dataset: {len(sorted_words)}\")\nprint(sorted_words[:10])\n\ncount_occurences = sum(words.values())\n\naccumulated = 0\ncounter = 0\n\nwhile accumulated < count_occurences * 0.8:\n  accumulated += words[sorted_words[counter]]\n  counter += 1\n\nprint(f\"The {counter * 100 / len(words)}% most common words \"\n      f\"account for the {accumulated * 100 / count_occurences}% of the occurrences\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T11:28:58.569984Z","iopub.execute_input":"2021-08-16T11:28:58.570342Z","iopub.status.idle":"2021-08-16T11:29:07.778686Z","shell.execute_reply.started":"2021-08-16T11:28:58.57031Z","shell.execute_reply":"2021-08-16T11:29:07.777748Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SECTION B.2**","metadata":{}},{"cell_type":"markdown","source":"## Recurrent Neural Network with Pytorch","metadata":{"id":"zVZ2PBxbvKQe"}},{"cell_type":"code","source":"# Set the device to use GPU\ndef set_device():\n  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n  if device != \"cuda\":\n    print(\"WARNING: For this notebook to perform best, \"\n          \"if possible, in the menu under `Runtime` -> \"\n          \"`Change runtime type.`  select `GPU` \")\n  else:\n    print(\"GPU is enabled in this notebook.\")\n\n  return device\n\n# Set the device (check if gpu is available)\ndevice = set_device()","metadata":{"id":"b71EOPSW3ZGX","execution":{"iopub.status.busy":"2021-08-16T11:29:09.661749Z","iopub.execute_input":"2021-08-16T11:29:09.662095Z","iopub.status.idle":"2021-08-16T11:29:09.667791Z","shell.execute_reply.started":"2021-08-16T11:29:09.662063Z","shell.execute_reply":"2021-08-16T11:29:09.666742Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First we will create a Dictionary (`word_to_idx`). This dictionary will map each Token (usually words) to an index (an integer number). We want to limit our dictionary to a certain number of tokens (`num_words_dict`), so we will include in our ditionary those with more occurrences.","metadata":{"id":"o-PDXYBeHkP8"}},{"cell_type":"code","source":"# Let us load the Glove embedded vectors by downloading it from the source (Stanford's website)\n# However the dataset isalso available freely on Kaggle so consider using that directly and skip this section\n# !wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n# !unzip glove.6B.zip\n# !wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n# !unzip glove.twitter.27B.zip","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:15:30.842136Z","iopub.execute_input":"2021-08-10T17:15:30.842456Z","iopub.status.idle":"2021-08-10T17:21:07.199352Z","shell.execute_reply.started":"2021-08-10T17:15:30.842429Z","shell.execute_reply":"2021-08-10T17:21:07.198429Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If you wish to use the general Wiki based word vectors embedding use the glove.6B.___d.txt, the ___ is\n# for how many dimensions do you want to ebed our word into.\n# glove = pd.read_csv('glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n# glove_embedding = {key: val.values for key, val in glove.T.items()}\n\n# If you wish to use the Tweets based word vectors embedding use the glove.twitter.27B.100d.txt\nglove = pd.read_csv('../input/glovetwitter27b100dtxt/glove.twitter.27B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\nglove_embedding = {key: val.values for key, val in glove.T.items()}\nglove_dim = 100\n\n# # If you wish to use the Tweets based word vectors embedding use the glove.twitter.27B.200d.txt\n# glove = pd.read_csv('../input/d/fullmetal26/glovetwitter27b100dtxt/glove.twitter.27B.200d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n# glove_embedding = {key: val.values for key, val in glove.T.items()}\n# glove_dim = 200","metadata":{"execution":{"iopub.status.busy":"2021-08-16T11:29:13.281726Z","iopub.execute_input":"2021-08-16T11:29:13.282071Z","iopub.status.idle":"2021-08-16T11:30:18.522693Z","shell.execute_reply.started":"2021-08-16T11:29:13.282042Z","shell.execute_reply":"2021-08-16T11:30:18.521761Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify the most common words to use for anaylsis\n#Let's select only the most used.\nnum_words_dict = 30000\n# We reserve two numbers for special tokens.\nmost_used_words = sorted_words[:num_words_dict-2]\n\n# We will add two extra Tokens to the dictionary, one for words outside the dictionary (`'UNK'`) and \n# one for padding the sequences (`'PAD'`).\n\n# dictionary to go from words to idx \nword_to_idx = {}\n# dictionary to go from idx to words (just in case) \nidx_to_word = {}\n\n# We include the special tokens first\nPAD_token = 0   \nUNK_token = 1\n\nword_to_idx['PAD'] = PAD_token\nword_to_idx['UNK'] = UNK_token\n\nidx_to_word[PAD_token] = 'PAD'\nidx_to_word[UNK_token] = 'UNK'\n\n# We popullate our dictionaries with the most used words\nfor num,word in enumerate(most_used_words):\n  word_to_idx[word] = num + 2\n  idx_to_word[num+2] = word\n    \n# The following function helps create a word embedding matrix    \ndef create_embedding_matrix(word_index,embedding_dict,dimension):\n  embedding_matrix=np.zeros((len(word_index)+1,dimension))\n \n  for word,index in word_index.items():\n    if word in embedding_dict:\n      embedding_matrix[index]=embedding_dict[word]\n  return embedding_matrix\n\n# Let us use the function to create a word-embedding matrix \n# My word_to_idx is the same as their word_index\nembedding_matrix=create_embedding_matrix(word_to_idx,embedding_dict=glove_embedding,dimension=glove_dim)\n\n\n# Our goal now is to transform each tweet from a sequence of tokens to a sequence of indexes. \n# These sequences of indexes will be the input to our pytorch model.\n\n# A function to convert list of tokens to list of indexes\ndef tokens_to_idx(sentences_tokens,word_to_idx):\n  sentences_idx = []\n  for sent in sentences_tokens:\n    sent_idx = []\n    for word in sent:\n      if word in word_to_idx:\n        sent_idx.append(word_to_idx[word])\n      else:\n        sent_idx.append(word_to_idx['UNK'])\n    sentences_idx.append(sent_idx)\n  return sentences_idx\n\nx_train_idx = tokens_to_idx(x_train_token,word_to_idx)\nx_test_idx = tokens_to_idx(x_test_token,word_to_idx)\n\n\n\n# We need all the sequences to have the same length. \n# To select an adequate sequence length, let's explore some statistics about the length of the tweets:\ntweet_lens = np.asarray([len(sentence) for sentence in x_train_idx])\nprint('Max tweet word length: ',tweet_lens.max())\nprint('Mean tweet word length: ',np.median(tweet_lens))\nprint('99% percent under: ',np.quantile(tweet_lens,0.99))","metadata":{"execution":{"iopub.status.busy":"2021-08-16T11:30:18.524245Z","iopub.execute_input":"2021-08-16T11:30:18.524611Z","iopub.status.idle":"2021-08-16T11:30:26.986663Z","shell.execute_reply.started":"2021-08-16T11:30:18.524573Z","shell.execute_reply":"2021-08-16T11:30:26.985212Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We cut the sequences which are larger than our chosen maximum length (`max_length`) and fill with zeros the ones that are shorter.\n# We choose the max length\nmax_length = 40 #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Change this in case you want to use inputs of different lengths.\n\n# A function to make all the sequence have the same lenght\n# Note that the output is a Numpy matrix\ndef padding(sentences, seq_len):\n features = np.zeros((len(sentences), seq_len),dtype=int)\n for ii, tweet in enumerate(sentences):\n   len_tweet = len(tweet) \n   if len_tweet != 0:\n     if len_tweet <= seq_len:\n       # If its shorter, we fill with zeros (the padding Token index)\n       features[ii, -len(tweet):] = np.array(tweet)[:seq_len]\n     if len_tweet > seq_len:\n       # If its larger, we take the last 'seq_len' indexes\n       features[ii, :] = np.array(tweet)[-seq_len:]\n return features\n\n\n# We convert our list of tokens into a numpy matrix\n# where all instances have the same lenght\nx_train_pad = padding(x_train_idx,max_length)\nx_test_pad = padding(x_test_idx,max_length)\n\n# We convert our target list a numpy matrix\ny_train_np = np.asarray(y_train)\ny_test_np = np.asarray(y_test)\n\n\n# Now, let's convert the data to pytorch format.\n\n# create Tensor datasets\ntrain_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train_np))\nvalid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test_np))\n\n# Batch size (this is an important hyperparameter)\nbatch_size = 100\n\n# dataloaders\n# make sure to SHUFFLE your data\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,drop_last = True)\nvalid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size,drop_last = True)\n\n\n# # Each batch of data in our traning proccess will have the folllowing format:\n# # Obtain one batch of training data\n# dataiter = iter(train_loader)\n# sample_x, sample_y = dataiter.next()\n\n# print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n# print('Sample input: \\n', sample_x)\n# print('Sample input: \\n', sample_y)","metadata":{"id":"n4lowj5J3bbU","execution":{"iopub.status.busy":"2021-08-16T11:30:35.079328Z","iopub.execute_input":"2021-08-16T11:30:35.079663Z","iopub.status.idle":"2021-08-16T11:30:44.970547Z","shell.execute_reply.started":"2021-08-16T11:30:35.079631Z","shell.execute_reply":"2021-08-16T11:30:44.969644Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GENERAL MODEL**","metadata":{}},{"cell_type":"code","source":"class SentimentRNN(nn.Module):\n    def __init__(self,no_layers,hidden_dim, output_dim, vocab_size, embedding_dim, embedding_matrix,\n                 model_name = 'LSTM', bi_directionality = False, use_pre_trained = True, \n                 tune_pre_trained = False, drop_prob=0.1):\n        super(SentimentRNN,self).__init__()\n\n        self.output_dim = output_dim\n        self.hidden_dim = hidden_dim\n        self.no_layers = no_layers\n        self.drop_prob = drop_prob\n        self.model_name = model_name\n        self.directions = bi_directionality\n        self.use_pre_trained = use_pre_trained\n        self.tune_pre_trained = tune_pre_trained\n        if use_pre_trained:\n            self.vocab_size = embedding_matrix.shape[0]\n            self.embedding_dim = embedding_matrix.shape[1]\n            # Embedding Layer\n            self.embedding = nn.Embedding(self.vocab_size,self.embedding_dim)\n            self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n            self.embedding.weight.requires_grad = self.tune_pre_trained\n        else:\n            self.vocab_size = vocab_size\n            self.embedding_dim = embedding_dim\n            # Embedding Layer\n            self.embedding = nn.Embedding(self.vocab_size,self.embedding_dim)\n    \n    # Next layers based ont he model chosen\n        if self.model_name == 'LSTM':\n      # LSTM Layers\n            self.lstm = nn.LSTM(input_size = self.embedding_dim,\n                              hidden_size = self.hidden_dim,\n                              num_layers = no_layers,\n                              bidirectional = self.directions,\n                              batch_first = True, \n                              dropout = self.drop_prob)\n        else:\n            self.gru = nn.GRU(input_size = self.embedding_dim,\n                            hidden_size = self.hidden_dim,\n                            num_layers = no_layers,\n                            bidirectional = self.directions,\n                            batch_first = True, \n                            dropout = self.drop_prob)\n      \n    \n    # Dropout layer\n        self.dropout = nn.Dropout(drop_prob)\n\n    # Linear and Sigmoid layer\n        if self.directions:\n            self.fc = nn.Linear(self.hidden_dim * 2, output_dim)\n        else:\n            self.fc = nn.Linear(self.hidden_dim * 2, output_dim)\n    \n        self.sig = nn.Sigmoid()\n      \n    def forward(self,x,hidden):\n        if self.model_name == 'LSTM':\n            batch_size = x.size(0)\n            embeds = self.embedding(x)\n            #Shape: [batch_size x max_length x embedding_dim]\n            # LSTM out\n            lstm_out, hidden = self.lstm(embeds, hidden)\n            # Shape: [batch_size x max_length x hidden_dim]\n            # Select the activation of the last Hidden Layer\n            lstm_out = lstm_out[:,-1,:].contiguous()\n            # Shape: [batch_size x hidden_dim]\n            ## You can instead average the activations across all the times\n            # lstm_out = torch.mean(lstm_out, 1).contiguous()\n            # Dropout and Fully connected layer\n            out = self.dropout(lstm_out)\n            out = self.fc(out)\n            # Sigmoid function\n            sig_out = self.sig(out)\n            # return last sigmoid output and hidden state\n            return sig_out, hidden\n        else:\n            batch_size = x.size(0)\n            self.h = self.init_hidden(batch_size)\n            # Embedding out\n            embeds = self.embedding(x)\n            #Shape: [batch_size x max_length x embedding_dim]\n            # GRU out\n            gru_out, self.h = self.gru(embeds, self.h)\n            # Shape: [batch_size x max_length x hidden_dim]\n            # Select the activation of the last Hidden Layer\n            gru_out = gru_out[:,-1,:].contiguous()\n            # Shape: [batch_size x hidden_dim]\n            # Dropout and Fully connected layer\n            out = self.dropout(gru_out)\n            out = self.fc(out)\n            # Sigmoid function\n            sig_out = self.sig(out)\n            # return last sigmoid output and hidden state\n            return sig_out\n\n    def init_hidden(self, batch_size):\n        ''' Initializes hidden state '''\n        if self.directions:\n            directionality = 2\n        else:\n            directionality = 1\n    \n        if self.model_name == 'LSTM':\n            # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n            # initialized to zero, for hidden state and cell state of LSTM\n            h0 = torch.zeros((self.no_layers * directionality, batch_size, self.hidden_dim)).to(device)\n            c0 = torch.zeros((self.no_layers * directionality, batch_size, self.hidden_dim)).to(device)\n\n            hidden = (h0,c0)\n            return hidden\n        else:\n            hidden = (torch.zeros((self.no_layers * directionality, batch_size, self.hidden_dim)).to(device))\n            return hidden","metadata":{"execution":{"iopub.status.busy":"2021-08-16T11:30:48.197214Z","iopub.execute_input":"2021-08-16T11:30:48.19757Z","iopub.status.idle":"2021-08-16T11:30:48.217392Z","shell.execute_reply.started":"2021-08-16T11:30:48.197532Z","shell.execute_reply":"2021-08-16T11:30:48.216464Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MODEL TRAINING**","metadata":{}},{"cell_type":"code","source":"def run_model(no_layers,hidden_dim, output_dim, vocab_size, embedding_dim, embedding_matrix,\n              model_name, bi_directionality, use_pre_trained, tune_pre_trained,\n              drop_prob, epochs, clip, lr, criterion, train_loader, valid_loader): \n\n    #######################################################################################\n    # Parameters of our network\n    # Let's define our model\n    model = SentimentRNN(no_layers,hidden_dim, output_dim, vocab_size, embedding_dim, embedding_matrix,\n                 model_name = model_name, bi_directionality = bi_directionality, use_pre_trained = use_pre_trained, \n                 tune_pre_trained = tune_pre_trained, drop_prob=drop_prob)\n    # Moving to gpu\n    model.to(device)\n    print(model)\n\n    #######################################################################################\n    # How many trainable parameters does our model have?\n    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n    params = sum([np.prod(p.size()) for p in model_parameters])\n    print('Total Number of parameters: ',params)\n\n\n    #######################################################################################\n    # loss and optimization functions\n    lr = lr\n    # Binary crossentropy is a good loss function for a binary classification problem\n    criterion = criterion\n    # We choose an Adam optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr) #>>>>> The optimizer function\n    \n    #######################################################################################\n    # Number of training Epochs\n    epochs = epochs\n    # Maximum absolute value accepted for the gradeint\n    clip = clip\n    # Initial Loss value (assumed big)\n    valid_loss_min = np.Inf\n\n    # Lists to follow the evolution of the loss and accuracy\n    epoch_tr_loss,epoch_vl_loss = [],[]\n    epoch_tr_acc,epoch_vl_acc = [],[]\n\n    # Train for a number of Epochs\n    for epoch in range(epochs):\n      train_losses = []\n      train_acc = 0.0\n      model.train()\n\n      for inputs, labels in train_loader:\n        \n        # Move batch inputs and labels to gpu\n        inputs, labels = inputs.to(device), labels.to(device)   \n        \n        if model.model_name == 'LSTM':\n            # Initialize hidden state \n            h = model.init_hidden(batch_size)\n            # Creating new variables for the hidden state\n            h = tuple([each.data.to(device) for each in h])\n            # Set gradient to zero\n            model.zero_grad()\n            # Compute model output\n            output,h = model(inputs,h)\n        else:\n            # Initialize the hidden layer for first forward\n            h = model.init_hidden(batch_size)\n            # Set gradient to zero\n            model.zero_grad()\n            # Compute model output\n            output = model(inputs,h)\n        \n        \n        # Calculate the loss and perform backprop\n        loss = criterion(output.squeeze(), labels.float())\n        loss.backward()\n        train_losses.append(loss.item())\n\n        # calculating accuracy\n        accuracy = acc(output,labels)\n        train_acc += accuracy\n\n        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n\n\n      # Evaluate on the validation set for this epoch \n      val_losses = []\n      val_acc = 0.0\n      model.eval()\n      for inputs, labels in valid_loader:\n\n        # Move batch inputs and labels to gpu\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        if model.model_name == 'LSTM':\n            # Initialize hidden state \n            val_h = model.init_hidden(batch_size)\n            # Creating new variables for the hidden state\n            val_h = tuple([each.data.to(device) for each in val_h])\n            # Set gradient to zero\n            model.zero_grad()\n            # Compute model output\n            output, val_h = model(inputs,val_h)\n        else:\n            # Initialize the hidden layer for first forward\n            val_h = model.init_hidden(batch_size)\n            # Set gradient to zero\n            model.zero_grad()\n            # Compute model output\n            output = model(inputs,val_h)\n\n        # Compute Loss\n        val_loss = criterion(output.squeeze(), labels.float())\n\n        val_losses.append(val_loss.item())\n\n        accuracy = acc(output,labels)\n        val_acc += accuracy\n\n      epoch_train_loss = np.mean(train_losses)\n      epoch_val_loss = np.mean(val_losses)\n      epoch_train_acc = train_acc/len(train_loader.dataset)\n      epoch_val_acc = val_acc/len(valid_loader.dataset)\n      epoch_tr_loss.append(epoch_train_loss)\n      epoch_vl_loss.append(epoch_val_loss)\n      epoch_tr_acc.append(epoch_train_acc)\n      epoch_vl_acc.append(epoch_val_acc)\n      print(f'Epoch {epoch+1}') \n      print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n      print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n      if epoch_val_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n        # torch.save(model.state_dict(), '../working/state_dict.pt')\n        valid_loss_min = epoch_val_loss\n      print(25*'==')\n    \n    return epoch_tr_acc, epoch_vl_acc, epoch_tr_loss, epoch_vl_loss","metadata":{"execution":{"iopub.status.busy":"2021-08-16T11:30:53.355Z","iopub.execute_input":"2021-08-16T11:30:53.355329Z","iopub.status.idle":"2021-08-16T11:30:53.373136Z","shell.execute_reply.started":"2021-08-16T11:30:53.355296Z","shell.execute_reply":"2021-08-16T11:30:53.372167Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to predict accuracy\ndef acc(pred,label):\n  pred = torch.round(pred.squeeze())\n  return torch.sum(pred == label.squeeze()).item()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T11:30:58.434936Z","iopub.execute_input":"2021-08-16T11:30:58.435261Z","iopub.status.idle":"2021-08-16T11:30:58.439881Z","shell.execute_reply.started":"2021-08-16T11:30:58.43523Z","shell.execute_reply":"2021-08-16T11:30:58.438622Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'LSTM'                 #>>>>> What kind of model? [Only LSTM or GRU possible]\n\nno_layers = 4                       #>>>>> How many layers in the RNN?\n\nhidden_dim = 32                     #>>>>> What dimension of the hidden layer?\n\nvocab_size = 30000                  #>>>>> Vacabulary size?\n\nembedding_dim = 32                  #>>>>> Embedding dimension?\n\nembedding_matrix = embedding_matrix #>>>>> What embedding matrix to use? \n# [Set to None if you do not wish to use pre-trained network]\n\nbi_directionality = True            #>>>>> Do you want to use bidirectional RNN? \n# [Default is False]\n\nuse_pre_trained = True             #>>>>> Should the model use the pre-trained embedding weights?\n\ntune_pre_trained = True             #>>>>> Should the model tune the pre-trained embedding weights?\n# [Default is False]\n\ndrop_prob=0.1                       #>>>>> What dropout probability to use, default is 0.1\n\nepochs = 1                          #>>>>> No. of epochs\n\nclip = 5                            #>>>>> Clippping the gradients\n\nlr = 0.001                          #>>>>> Learning rate\n\ncriterion = nn.BCELoss()            #>>>>> Criterion for calculating the loss\n\nout_dim = 1\n\nepoch_tr_acc, epoch_vl_acc, epoch_tr_loss, epoch_vl_loss = run_model(no_layers,hidden_dim, out_dim, vocab_size, embedding_dim, embedding_matrix,\n                                                                      model_name, bi_directionality, use_pre_trained, tune_pre_trained,\n                                                                      drop_prob, epochs, clip, lr, criterion, train_loader, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T13:01:38.809337Z","iopub.execute_input":"2021-08-16T13:01:38.8097Z","iopub.status.idle":"2021-08-16T13:08:16.360178Z","shell.execute_reply.started":"2021-08-16T13:01:38.809666Z","shell.execute_reply":"2021-08-16T13:08:16.357861Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looping through the whole array of variables\nfor model_name in ['GRU']:\n    for no_layers in [4]:\n        for hidden_dim in [32,64,128]:\n            for bi_directionality in [True]:#, False]:\n                for tune_pre_trained in [True]:#, False]:\n                    for drop_prob in [0.1, 0.3]:\n                        embedding_matrix = embedding_matrix\n                        use_pre_trained = True\n                        epochs = 1\n                        vocab_size = 30000\n                        embedding_dim = 32\n                        for lr in [0.001, 0.005]:\n                            criterion = nn.BCELoss()\n                            out_dim = 1\n                            clip = 5\n                            print(\"##################################################################################################################################################\\n\")\n                            print(f\"The Model is {model_name} with {no_layers} layers, each of dimension {hidden_dim} with bi-directionality set to {bi_directionality} and pre-tuning set to {tune_pre_trained}.\")\n                            print(f\"The dropout probability is {drop_prob} and learning rate is {lr}.\")\n                            epoch_tr_acc, epoch_vl_acc, epoch_tr_loss, epoch_vl_loss = run_model(no_layers,hidden_dim, out_dim, vocab_size, embedding_dim, embedding_matrix,\n                                                                      model_name, bi_directionality, use_pre_trained, tune_pre_trained,\n                                                                      drop_prob, epochs, clip, lr, criterion, train_loader, valid_loader)\n                            del epoch_tr_acc, epoch_vl_acc, epoch_tr_loss, epoch_vl_loss\n                            print(\"##################################################################################################################################################\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T11:31:20.230933Z","iopub.execute_input":"2021-08-16T11:31:20.231256Z","iopub.status.idle":"2021-08-16T13:01:05.789355Z","shell.execute_reply.started":"2021-08-16T11:31:20.231227Z","shell.execute_reply":"2021-08-16T13:01:05.788383Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let us plot some results**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\ndf2 = pd.read_csv(\"../input/val-acc/data_val_acc.csv\")\ndf2.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-16T13:44:29.797924Z","iopub.execute_input":"2021-08-16T13:44:29.798243Z","iopub.status.idle":"2021-08-16T13:44:29.809261Z","shell.execute_reply.started":"2021-08-16T13:44:29.798213Z","shell.execute_reply":"2021-08-16T13:44:29.808025Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['type_of_Model', 'no_of_hidden_layers', 'hidden_layer_dim',\n       'no_of_parameters', 'dropout_rate', 'learning_rate', 'validation_acc'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"\nfig, axs = plt.subplots(1,4, figsize = (20,5))\nsns.barplot(x = 'no_of_hidden_layers', y = 'validation_acc', data = df2, hue = 'type_of_Model',\n            palette = 'hls',\n            capsize = 0.05,             \n            saturation = 8,             \n            errcolor = 'gray', errwidth = 2,  \n            ci = 95, ax = axs[0]\n            )\naxs[0].set_ylim(78,83)\nsns.barplot(x = 'hidden_layer_dim', y = 'validation_acc', data = df2, hue = 'type_of_Model',\n            palette = 'hls',\n            capsize = 0.05,             \n            saturation = 8,             \n            errcolor = 'gray', errwidth = 2,  \n            ci = 95, ax = axs[1]\n            )\naxs[1].set_ylim(78,83)\nsns.barplot(x = 'learning_rate', y = 'validation_acc', data = df2, hue = 'type_of_Model',\n            palette = 'hls',\n            capsize = 0.05,             \n            saturation = 8,             \n            errcolor = 'gray', errwidth = 2,  \n            ci = 95, ax = axs[2]\n            )\naxs[2].set_ylim(78,83)\nsns.barplot(x = 'dropout_rate', y = 'validation_acc', data = df2, hue = 'type_of_Model',\n            palette = 'hls',\n            capsize = 0.05,             \n            saturation = 8,             \n            errcolor = 'gray', errwidth = 2,  \n            ci = 95, ax = axs[3]\n            )\naxs[3].set_ylim(78,83)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T13:52:41.074490Z","iopub.execute_input":"2021-08-16T13:52:41.074847Z","iopub.status.idle":"2021-08-16T13:52:42.628718Z","shell.execute_reply.started":"2021-08-16T13:52:41.074816Z","shell.execute_reply":"2021-08-16T13:52:42.627854Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1440x360 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"**LSTM UNI-DIRECTIONAL**","metadata":{}},{"cell_type":"code","source":"# Let us a LSTM RNN using the pre-trianed embedding from GLOVE.\nclass SentimentLSTM(nn.Module):\n  def __init__(self, no_layers, hidden_dim, embedding_matrix, drop_prob=0.1):\n    super(SentimentLSTM,self).__init__()\n\n    self.output_dim = output_dim\n    self.hidden_dim = hidden_dim\n    self.no_layers = no_layers\n    self.drop_prob = drop_prob\n    self.vocab_size = embedding_matrix.shape[0]\n    self.embedding_dim = embedding_matrix.shape[1]\n    \n    # Embedding Layer\n    self.embedding=nn.Embedding(self.vocab_size,self.embedding_dim)\n    self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n    self.embedding.weight.requires_grad=True\n    \n    # LSTM Layers\n    self.lstm = nn.LSTM(input_size=self.embedding_dim,hidden_size=self.hidden_dim,\n                        num_layers=no_layers, bidirectional=False, batch_first=True, \n                        dropout=self.drop_prob)\n\n    # Dropout layer\n    self.dropout = nn.Dropout(drop_prob)\n\n    # Linear and Sigmoid layer\n    self.fc = nn.Linear(self.hidden_dim, output_dim)\n    self.sig = nn.Sigmoid()\n      \n  def forward(self,x,hidden):\n    \n    batch_size = x.size(0)\n    \n    embeds = self.embedding(x)\n    #Shape: [batch_size x max_length x embedding_dim]\n    \n    # LSTM out\n    lstm_out, hidden = self.lstm(embeds, hidden)\n    # Shape: [batch_size x max_length x hidden_dim]\n    \n    # Select the activation of the last Hidden Layer\n#     lstm_out = lstm_out[:,-1,:].contiguous()\n    # Shape: [batch_size x hidden_dim]\n\n    ## You can instead average the activations across all the times\n    lstm_out = torch.mean(lstm_out, 1).contiguous()\n\n    # Dropout and Fully connected layer\n    out = self.dropout(lstm_out)\n    out = self.fc(out)\n\n    # Sigmoid function\n    sig_out = self.sig(out)\n\n    # return last sigmoid output and hidden state\n    return sig_out, hidden\n\n  def init_hidden(self, batch_size):\n    ''' Initializes hidden state '''\n    # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n    # initialized to zero, for hidden state and cell state of LSTM\n    h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n    c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n    hidden = (h0,c0)\n    return hidden\n\n#######################################################################################\n# Parameters of our network\n# Size of our vocabulary\n# Number of stacked LSTM layers\nno_layers = 2\n# Dimension of the hidden layer in LSTMs\nhidden_dim = 64\n# Dropout parameter for regularization\noutput_dim = 1\n# Dropout parameter for regularization\ndrop_prob = 0.25\n# Let's define our model\nmodel = SentimentLSTM(no_layers, hidden_dim,embedding_matrix, drop_prob=drop_prob)\n# Moving to gpu\nmodel.to(device)\nprint(model)\n\n#######################################################################################\n# How many trainable parameters does our model have?\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint('Total Number of parameters: ',params)\n\n#######################################################################################\n# Let us set up some parameters here.\n# loss and optimization functions\nlr = 0.005\n# Binary crossentropy is a good loss function for a binary classification problem\ncriterion = nn.BCELoss()\n# We choose an Adam optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n#######################################################################################\n# function to predict accuracy\ndef acc(pred,label):\n  pred = torch.round(pred.squeeze())\n  return torch.sum(pred == label.squeeze()).item()\n\n#######################################################################################\n#lets run the model for one epoch to test its ability to run.\n# Number of training Epochs\nepochs = 3\n# Maximum absolute value accepted for the gradeint\nclip = 5\n# Initial Loss value (assumed big)\nvalid_loss_min = np.Inf\n# Lists to follow the evolution of the loss and accuracy\nepoch_tr_loss,epoch_vl_loss = [],[]\nepoch_tr_acc,epoch_vl_acc = [],[]\n# Train for a number of Epochs\nfor epoch in range(epochs):\n  train_losses = []\n  train_acc = 0.0\n  model.train()\n  \n  for inputs, labels in train_loader:\n\n    # Initialize hidden state \n    h = model.init_hidden(batch_size)\n    # Creating new variables for the hidden state\n    h = tuple([each.data.to(device) for each in h])\n\n    # Move batch inputs and labels to gpu\n    inputs, labels = inputs.to(device), labels.to(device)   \n\n    # Set gradient to zero\n    model.zero_grad()\n\n    # Compute model output\n    output,h = model(inputs,h)\n\n    # Calculate the loss and perform backprop\n    loss = criterion(output.squeeze(), labels.float())\n    loss.backward()\n    train_losses.append(loss.item())\n\n    # calculating accuracy\n    accuracy = acc(output,labels)\n    train_acc += accuracy\n\n    #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n    nn.utils.clip_grad_norm_(model.parameters(), clip)\n    optimizer.step()\n\n  \n  # Evaluate on the validation set for this epoch \n  val_losses = []\n  val_acc = 0.0\n  model.eval()\n  for inputs, labels in valid_loader:\n\n    # Initialize hidden state \n    val_h = model.init_hidden(batch_size)\n    val_h = tuple([each.data.to(device) for each in val_h])\n\n    # Move batch inputs and labels to gpu\n    inputs, labels = inputs.to(device), labels.to(device)\n\n    # Compute model output\n    output, val_h = model(inputs, val_h)\n\n    # Compute Loss\n    val_loss = criterion(output.squeeze(), labels.float())\n\n    val_losses.append(val_loss.item())\n\n    accuracy = acc(output,labels)\n    val_acc += accuracy\n          \n  epoch_train_loss = np.mean(train_losses)\n  epoch_val_loss = np.mean(val_losses)\n  epoch_train_acc = train_acc/len(train_loader.dataset)\n  epoch_val_acc = val_acc/len(valid_loader.dataset)\n  epoch_tr_loss.append(epoch_train_loss)\n  epoch_vl_loss.append(epoch_val_loss)\n  epoch_tr_acc.append(epoch_train_acc)\n  epoch_vl_acc.append(epoch_val_acc)\n  print(f'Epoch {epoch+1}') \n  print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n  print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n  if epoch_val_loss <= valid_loss_min:\n    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n    # torch.save(model.state_dict(), '../working/state_dict.pt')\n    valid_loss_min = epoch_val_loss\n  print(25*'==')\n\n#######################################################################################\n# plot the results from the training and validation accuracies\nfig = plt.figure(figsize = (20, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epoch_tr_acc, label='Train Acc')\nplt.plot(epoch_vl_acc, label='Validation Acc')\n# plt.ylim([70, 80])\nplt.title(\"Accuracy\")\nplt.legend()\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch_tr_loss, label='Train loss')\nplt.plot(epoch_vl_loss, label='Validation loss')\nplt.title(\"Loss\")\nplt.legend()\nplt.grid()\n\nplt.show()","metadata":{"id":"k1T6TCkNv3vh","execution":{"iopub.status.busy":"2021-08-13T14:37:34.377247Z","iopub.execute_input":"2021-08-13T14:37:34.37756Z","iopub.status.idle":"2021-08-13T14:43:33.708849Z","shell.execute_reply.started":"2021-08-13T14:37:34.377533Z","shell.execute_reply":"2021-08-13T14:43:33.708089Z"},"_kg_hide-input":false,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GRU UNI-DIRECTIONAL**","metadata":{}},{"cell_type":"code","source":"class SentimentGRU(nn.Module):\n  def __init__(self,no_layers,hidden_dim,embedding_matrix,drop_prob = 0.01):\n    super(SentimentGRU,self).__init__()\n\n    self.output_dim = output_dim\n    self.hidden_dim = hidden_dim\n    self.no_layers = no_layers\n    self.drop_prob = drop_prob\n    self.vocab_size = embedding_matrix.shape[0]\n    self.embedding_dim = embedding_matrix.shape[1]\n    \n    # Embedding layer\n    self.embedding=nn.Embedding(self.vocab_size,self.embedding_dim)\n    self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n    self.embedding.weight.requires_grad=True\n\n    # GRU Layers\n    self.gru = nn.GRU(input_size= self.embedding_dim,hidden_size=self.hidden_dim,\n                        num_layers=no_layers, bidirectional=False, batch_first=True, \n                        dropout=self.drop_prob)\n\n    # Dropout layer\n    self.dropout = nn.Dropout(drop_prob)\n\n    # Linear and Sigmoid layer\n    self.fc = nn.Linear(self.hidden_dim, output_dim)\n    self.sig = nn.Sigmoid()\n      \n  def forward(self,x,hidden):\n    batch_size = x.size(0)\n    self.h = self.init_hidden(batch_size)\n    \n    # Embedding out\n    embeds = self.embedding(x)\n    #Shape: [batch_size x max_length x embedding_dim]\n\n    # GRU out\n    gru_out, self.h = self.gru(embeds, self.h)\n    # Shape: [batch_size x max_length x hidden_dim]\n\n    # Select the activation of the last Hidden Layer\n    gru_out = gru_out[:,-1,:].contiguous()\n    # Shape: [batch_size x hidden_dim]\n\n    # Dropout and Fully connected layer\n    out = self.dropout(gru_out)\n    out = self.fc(out)\n\n    # Sigmoid function\n    sig_out = self.sig(out)\n\n    # return last sigmoid output and hidden state\n    return sig_out\n\n  def init_hidden(self, batch_size):\n    hidden = (torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device))\n    return hidden\n\n#######################################################################################\n# Parameters of our network\n# Number of stacked GRU layers\nno_layers = 3\n# Dimension of the hidden layer in LSTMs\nhidden_dim = 128\n# Dropout parameter for regularization\noutput_dim = 1\n# Dropout parameter for regularization\ndrop_prob = 0.25\n# Let's define our model\nmodel = SentimentGRU(no_layers, hidden_dim,\n                     embedding_matrix, drop_prob=drop_prob)\n# Moving to gpu\nmodel.to(device)\nprint(model)\n\n# How many trainable parameters does our model have?\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint('Total Number of parameters: ',params)\n\n#######################################################################################\n# loss and optimization functions\nlr = 0.001\n# Binary crossentropy is a good loss function for a binary classification problem\ncriterion = nn.BCELoss()\n# We choose an Adam optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n# function to predict accuracy\ndef acc(pred,label):\n  pred = torch.round(pred.squeeze())\n  return torch.sum(pred == label.squeeze()).item()\n\n#######################################################################################\n# Number of training Epochs\nepochs = 3\n# Maximum absolute value accepted for the gradeint\nclip = 5\n# Initial Loss value (assumed big)\nvalid_loss_min = np.Inf\n\n# Lists to follow the evolution of the loss and accuracy\nepoch_tr_loss,epoch_vl_loss = [],[]\nepoch_tr_acc,epoch_vl_acc = [],[]\n\n# Train for a number of Epochs\nfor epoch in range(epochs):\n  train_losses = []\n  train_acc = 0.0\n  model.train()\n  \n  for inputs, labels in train_loader:\n\n    # Move batch inputs and labels to gpu\n    inputs, labels = inputs.to(device), labels.to(device)   \n    \n    # Initialize the hidden layer for first forward\n    h = model.init_hidden(batch_size)\n    \n    # Set gradient to zero\n    model.zero_grad()\n\n    # Compute model output\n    output = model(inputs,h)\n\n    # Calculate the loss and perform backprop\n    loss = criterion(output.squeeze(), labels.float())\n    loss.backward()\n    train_losses.append(loss.item())\n\n    # calculating accuracy\n    accuracy = acc(output,labels)\n    train_acc += accuracy\n\n    #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n    nn.utils.clip_grad_norm_(model.parameters(), clip)\n    optimizer.step()\n\n  \n  # Evaluate on the validation set for this epoch \n  val_losses = []\n  val_acc = 0.0\n  model.eval()\n  for inputs, labels in valid_loader:\n\n    # Move batch inputs and labels to gpu\n    inputs, labels = inputs.to(device), labels.to(device)\n    \n    # Initialize the hidden layer for first forward\n    val_h = model.init_hidden(batch_size)\n    \n    # Compute model output\n    output = model(inputs, val_h)\n\n    # Compute Loss\n    val_loss = criterion(output.squeeze(), labels.float())\n\n    val_losses.append(val_loss.item())\n\n    accuracy = acc(output,labels)\n    val_acc += accuracy\n          \n  epoch_train_loss = np.mean(train_losses)\n  epoch_val_loss = np.mean(val_losses)\n  epoch_train_acc = train_acc/len(train_loader.dataset)\n  epoch_val_acc = val_acc/len(valid_loader.dataset)\n  epoch_tr_loss.append(epoch_train_loss)\n  epoch_vl_loss.append(epoch_val_loss)\n  epoch_tr_acc.append(epoch_train_acc)\n  epoch_vl_acc.append(epoch_val_acc)\n  print(f'Epoch {epoch+1}') \n  print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n  print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n  if epoch_val_loss <= valid_loss_min:\n    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n    # torch.save(model.state_dict(), '../working/state_dict.pt')\n    valid_loss_min = epoch_val_loss\n  print(25*'==')\n\n#######################################################################################\nfig = plt.figure(figsize = (20, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epoch_tr_acc, label='Train Acc')\nplt.plot(epoch_vl_acc, label='Validation Acc')\nplt.title(\"Accuracy\")\nplt.legend()\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch_tr_loss, label='Train loss')\nplt.plot(epoch_vl_loss, label='Validation loss')\nplt.title(\"Loss\")\nplt.legend()\nplt.grid()\n\nplt.show()","metadata":{"id":"HjHgDrNs3n1R","outputId":"7fab01d5-1676-4f5b-9e30-b45181d62dff","execution":{"iopub.status.busy":"2021-08-13T14:04:36.326404Z","iopub.execute_input":"2021-08-13T14:04:36.326744Z","iopub.status.idle":"2021-08-13T14:15:12.522415Z","shell.execute_reply.started":"2021-08-13T14:04:36.326715Z","shell.execute_reply":"2021-08-13T14:15:12.521584Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LSTM BI-DIRECTIONAL**","metadata":{}},{"cell_type":"code","source":"class SentimentLSTM_bi(nn.Module):\n  def __init__(self,no_layers,hidden_dim,embedding_matrix,drop_prob=0.1):\n    super(SentimentLSTM_bi,self).__init__()\n\n    self.output_dim = output_dim\n    self.hidden_dim = hidden_dim\n    self.no_layers = no_layers\n    self.drop_prob = drop_prob\n    self.vocab_size = embedding_matrix.shape[0]\n    self.embedding_dim = embedding_matrix.shape[1]\n    \n    # Embedding Layer\n    self.embedding=nn.Embedding(self.vocab_size,self.embedding_dim)\n    self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n    self.embedding.weight.requires_grad=True\n\n    # LSTM Layers\n    self.lstm = nn.LSTM(input_size=self.embedding_dim,hidden_size=self.hidden_dim,\n                        num_layers=no_layers, bidirectional=True, batch_first=True, \n                        dropout=self.drop_prob)\n    \n    # Dropout layer\n    self.dropout = nn.Dropout(drop_prob)\n\n    # Linear and Sigmoid layer\n    self.fc = nn.Linear(self.hidden_dim * 2, output_dim)\n    self.sig = nn.Sigmoid()\n      \n  def forward(self,x,hidden):\n    batch_size = x.size(0)\n    embeds = self.embedding(x)\n    #Shape: [batch_size x max_length x embedding_dim]\n    \n    # LSTM out\n    lstm_out, hidden = self.lstm(embeds, hidden)\n    # Shape: [batch_size x max_length x hidden_dim]\n    \n    # Select the activation of the last Hidden Layer\n    lstm_out = lstm_out[:,-1,:].contiguous()\n    # Shape: [batch_size x hidden_dim]\n\n    ## You can instead average the activations across all the times\n    # lstm_out = torch.mean(lstm_out, 1).contiguous()\n\n    # Dropout and Fully connected layer\n    out = self.dropout(lstm_out)\n    out = self.fc(out)\n\n    # Sigmoid function\n    sig_out = self.sig(out)\n\n    # return last sigmoid output and hidden state\n    return sig_out, hidden\n\n  def init_hidden(self, batch_size):\n    ''' Initializes hidden state '''\n    # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n    # initialized to zero, for hidden state and cell state of LSTM\n    h0 = torch.zeros((self.no_layers * 2,batch_size, self.hidden_dim)).to(device)\n    c0 = torch.zeros((self.no_layers * 2,batch_size, self.hidden_dim)).to(device)\n    \n    hidden = (h0,c0)\n    return hidden\n\n#######################################################################################\n# Parameters of our network\n# Number of stacked LSTM layers\nno_layers = 3\n# Dimension of the hidden layer in LSTMs\nhidden_dim = 64\n# Dropout parameter for regularization\noutput_dim = 1\n# Dropout parameter for regularization\ndrop_prob = 0.25\n# Let's define our model\nmodel = SentimentLSTM_bi(no_layers, hidden_dim,embedding_matrix, drop_prob=drop_prob)\n# Moving to gpu\nmodel.to(device)\nprint(model)\n\n#######################################################################################\n# How many trainable parameters does our model have?\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint('Total Number of parameters: ',params)\n\n# loss and optimization functions\nlr = 0.005\n\n# Binary crossentropy is a good loss function for a binary classification problem\ncriterion = nn.BCELoss()\n\n# We choose an Adam optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n# function to predict accuracy\ndef acc(pred,label):\n  pred = torch.round(pred.squeeze())\n  return torch.sum(pred == label.squeeze()).item()\n\n#######################################################################################\n#lets run the model for one epoch to test its ability to run.\n# Number of training Epochs\nepochs = 5\n# Maximum absolute value accepted for the gradeint\nclip = 5\n# Initial Loss value (assumed big)\nvalid_loss_min = np.Inf\n# Lists to follow the evolution of the loss and accuracy\nepoch_tr_loss,epoch_vl_loss = [],[]\nepoch_tr_acc,epoch_vl_acc = [],[]\n# Train for a number of Epochs\nfor epoch in range(epochs):\n  train_losses = []\n  train_acc = 0.0\n  model.train()\n  \n  for inputs, labels in train_loader:\n\n    # Initialize hidden state \n    h = model.init_hidden(batch_size)\n    # Creating new variables for the hidden state\n    h = tuple([each.data.to(device) for each in h])\n\n    # Move batch inputs and labels to gpu\n    inputs, labels = inputs.to(device), labels.to(device)   \n\n    # Set gradient to zero\n    model.zero_grad()\n\n    # Compute model output\n    output,h = model(inputs,h)\n\n    # Calculate the loss and perform backprop\n    loss = criterion(output.squeeze(), labels.float())\n    loss.backward()\n    train_losses.append(loss.item())\n\n    # calculating accuracy\n    accuracy = acc(output,labels)\n    train_acc += accuracy\n\n    #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n    nn.utils.clip_grad_norm_(model.parameters(), clip)\n    optimizer.step()\n\n  \n  # Evaluate on the validation set for this epoch \n  val_losses = []\n  val_acc = 0.0\n  model.eval()\n  for inputs, labels in valid_loader:\n\n    # Initialize hidden state \n    val_h = model.init_hidden(batch_size)\n    val_h = tuple([each.data.to(device) for each in val_h])\n\n    # Move batch inputs and labels to gpu\n    inputs, labels = inputs.to(device), labels.to(device)\n\n    # Compute model output\n    output, val_h = model(inputs, val_h)\n\n    # Compute Loss\n    val_loss = criterion(output.squeeze(), labels.float())\n\n    val_losses.append(val_loss.item())\n\n    accuracy = acc(output,labels)\n    val_acc += accuracy\n          \n  epoch_train_loss = np.mean(train_losses)\n  epoch_val_loss = np.mean(val_losses)\n  epoch_train_acc = train_acc/len(train_loader.dataset)\n  epoch_val_acc = val_acc/len(valid_loader.dataset)\n  epoch_tr_loss.append(epoch_train_loss)\n  epoch_vl_loss.append(epoch_val_loss)\n  epoch_tr_acc.append(epoch_train_acc)\n  epoch_vl_acc.append(epoch_val_acc)\n  print(f'Epoch {epoch+1}') \n  print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n  print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n  if epoch_val_loss <= valid_loss_min:\n    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n    # torch.save(model.state_dict(), '../working/state_dict.pt')\n    valid_loss_min = epoch_val_loss\n  print(25*'==')\n\n#######################################################################################\n# plot the results from the training and validation accuracies\nfig = plt.figure(figsize = (20, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epoch_tr_acc, label='Train Acc')\nplt.plot(epoch_vl_acc, label='Validation Acc')\n# plt.ylim([70, 80])\nplt.title(\"Accuracy\")\nplt.legend()\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch_tr_loss, label='Train loss')\nplt.plot(epoch_vl_loss, label='Validation loss')\nplt.title(\"Loss\")\nplt.legend()\nplt.grid()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T15:55:41.525859Z","iopub.execute_input":"2021-08-12T15:55:41.526242Z","iopub.status.idle":"2021-08-12T16:26:57.054457Z","shell.execute_reply.started":"2021-08-12T15:55:41.52621Z","shell.execute_reply":"2021-08-12T16:26:57.052933Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GRU BI-DIRECTIONAL**","metadata":{}},{"cell_type":"code","source":"class SentimentGRU_bi(nn.Module):\n  def __init__(self,no_layers,hidden_dim,embedding_matrix,drop_prob = 0.01):\n    super(SentimentGRU_bi,self).__init__()\n\n    self.output_dim = output_dim\n    self.hidden_dim = hidden_dim\n    self.no_layers = no_layers\n    self.drop_prob = drop_prob\n    self.vocab_size = embedding_matrix.shape[0]\n    self.embedding_dim = embedding_matrix.shape[1]\n    \n    # Embedding layer\n    self.embedding=nn.Embedding(self.vocab_size,self.embedding_dim)\n    self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n    self.embedding.weight.requires_grad=True\n\n    # GRU Layers\n    self.gru = nn.GRU(input_size= self.embedding_dim,hidden_size=self.hidden_dim,\n                        num_layers=no_layers, bidirectional=True, batch_first=True, \n                        dropout=self.drop_prob)\n\n    # Dropout layer\n    self.dropout = nn.Dropout(drop_prob)\n\n    # Linear and Sigmoid layer\n    self.fc = nn.Linear(self.hidden_dim * 2, output_dim)\n    self.sig = nn.Sigmoid()\n      \n  def forward(self,x,hidden):\n    batch_size = x.size(0)\n    self.h = self.init_hidden(batch_size)\n    \n    # Embedding out\n    embeds = self.embedding(x)\n    #Shape: [batch_size x max_length x embedding_dim]\n\n    # GRU out\n    gru_out, self.h = self.gru(embeds, self.h)\n    # Shape: [batch_size x max_length x hidden_dim]\n\n    # Select the activation of the last Hidden Layer\n    gru_out = gru_out[:,-1,:].contiguous()\n    # Shape: [batch_size x hidden_dim]\n\n    # Dropout and Fully connected layer\n    out = self.dropout(gru_out)\n    out = self.fc(out)\n\n    # Sigmoid function\n    sig_out = self.sig(out)\n\n    # return last sigmoid output and hidden state\n    return sig_out\n\n  def init_hidden(self, batch_size):\n    hidden = (torch.zeros((self.no_layers * 2,batch_size,self.hidden_dim)).to(device))\n    return hidden\n\n#######################################################################################\n# Parameters of our network\n# Number of stacked GRU layers\nno_layers = 3\n# Dimension of the hidden layer in LSTMs\nhidden_dim = 64\n# Dropout parameter for regularization\noutput_dim = 1\n# Dropout parameter for regularization\ndrop_prob = 0.25\n# Let's define our model\nmodel = SentimentGRU_bi(no_layers, hidden_dim,\n                     embedding_matrix, drop_prob=drop_prob)\n# Moving to gpu\nmodel.to(device)\nprint(model)\n\n# How many trainable parameters does our model have?\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint('Total Number of parameters: ',params)\n\n#######################################################################################\n# loss and optimization functions\nlr = 0.001\n# Binary crossentropy is a good loss function for a binary classification problem\ncriterion = nn.BCELoss()\n# We choose an Adam optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n# function to predict accuracy\ndef acc(pred,label):\n  pred = torch.round(pred.squeeze())\n  return torch.sum(pred == label.squeeze()).item()\n\n#######################################################################################\n# Number of training Epochs\nepochs = 1\n# Maximum absolute value accepted for the gradeint\nclip = 5\n# Initial Loss value (assumed big)\nvalid_loss_min = np.Inf\n\n# Lists to follow the evolution of the loss and accuracy\nepoch_tr_loss,epoch_vl_loss = [],[]\nepoch_tr_acc,epoch_vl_acc = [],[]\n\n# Train for a number of Epochs\nfor epoch in range(epochs):\n  train_losses = []\n  train_acc = 0.0\n  model.train()\n  \n  for inputs, labels in train_loader:\n\n    # Move batch inputs and labels to gpu\n    inputs, labels = inputs.to(device), labels.to(device)   \n    \n    # Initialize the hidden layer for first forward\n    h = model.init_hidden(batch_size)\n    \n    # Set gradient to zero\n    model.zero_grad()\n\n    # Compute model output\n    output = model(inputs,h)\n\n    # Calculate the loss and perform backprop\n    loss = criterion(output.squeeze(), labels.float())\n    loss.backward()\n    train_losses.append(loss.item())\n\n    # calculating accuracy\n    accuracy = acc(output,labels)\n    train_acc += accuracy\n\n    #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n    nn.utils.clip_grad_norm_(model.parameters(), clip)\n    optimizer.step()\n\n  \n  # Evaluate on the validation set for this epoch \n  val_losses = []\n  val_acc = 0.0\n  model.eval()\n  for inputs, labels in valid_loader:\n\n    # Move batch inputs and labels to gpu\n    inputs, labels = inputs.to(device), labels.to(device)\n    \n    # Initialize the hidden layer for first forward\n    val_h = model.init_hidden(batch_size)\n    \n    # Compute model output\n    output = model(inputs, val_h)\n\n    # Compute Loss\n    val_loss = criterion(output.squeeze(), labels.float())\n\n    val_losses.append(val_loss.item())\n\n    accuracy = acc(output,labels)\n    val_acc += accuracy\n          \n  epoch_train_loss = np.mean(train_losses)\n  epoch_val_loss = np.mean(val_losses)\n  epoch_train_acc = train_acc/len(train_loader.dataset)\n  epoch_val_acc = val_acc/len(valid_loader.dataset)\n  epoch_tr_loss.append(epoch_train_loss)\n  epoch_vl_loss.append(epoch_val_loss)\n  epoch_tr_acc.append(epoch_train_acc)\n  epoch_vl_acc.append(epoch_val_acc)\n  print(f'Epoch {epoch+1}') \n  print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n  print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n  if epoch_val_loss <= valid_loss_min:\n    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n    # torch.save(model.state_dict(), '../working/state_dict.pt')\n    valid_loss_min = epoch_val_loss\n  print(25*'==')\n\n#######################################################################################\nfig = plt.figure(figsize = (20, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epoch_tr_acc, label='Train Acc')\nplt.plot(epoch_vl_acc, label='Validation Acc')\nplt.title(\"Accuracy\")\nplt.legend()\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch_tr_loss, label='Train loss')\nplt.plot(epoch_vl_loss, label='Validation loss')\nplt.title(\"Loss\")\nplt.legend()\nplt.grid()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T14:16:51.440826Z","iopub.execute_input":"2021-08-13T14:16:51.441152Z","iopub.status.idle":"2021-08-13T14:22:01.97689Z","shell.execute_reply.started":"2021-08-13T14:16:51.441122Z","shell.execute_reply":"2021-08-13T14:22:01.976077Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PLOTTING**","metadata":{}},{"cell_type":"code","source":"\n#######################################################################################\nfig = plt.figure(figsize = (20, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epoch_tr_acc, label='Train Acc')\nplt.plot(epoch_vl_acc, label='Validation Acc')\nplt.title(\"Accuracy\")\nplt.legend()\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch_tr_loss, label='Train loss')\nplt.plot(epoch_vl_loss, label='Validation loss')\nplt.title(\"Loss\")\nplt.legend()\nplt.grid()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T15:35:59.520077Z","iopub.execute_input":"2021-08-13T15:35:59.520429Z","iopub.status.idle":"2021-08-13T15:35:59.793386Z","shell.execute_reply.started":"2021-08-13T15:35:59.520399Z","shell.execute_reply":"2021-08-13T15:35:59.792442Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}